{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "omWBpXB9kJfI",
        "e7W7OqGNkO_n"
      ],
      "authorship_tag": "ABX9TyNVcL6kGvjqTrI0nRWP2O8j"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omWBpXB9kJfI",
        "colab_type": "text"
      },
      "source": [
        "## Spark setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqUjdzxOxjS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q http://apache.forsale.plus/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbF-156IyN8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xf /content/spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwltzcJK5QBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcHgm_-9zaFd",
        "colab_type": "code",
        "outputId": "6094c127-1a4a-450b-bb22-85e2b1508589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install -q findspark\n",
        "!pip install -q pyspark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 217.8MB 60kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 48.0MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV8frwhSjoaa",
        "colab_type": "code",
        "outputId": "1445db36-d029-45d0-db4a-0627c2d0d979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/databricks/Spark-The-Definitive-Guide.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Spark-The-Definitive-Guide'...\n",
            "remote: Enumerating objects: 2035, done.\u001b[K\n",
            "remote: Total 2035 (delta 0), reused 0 (delta 0), pack-reused 2035\u001b[K\n",
            "Receiving objects: 100% (2035/2035), 523.88 MiB | 31.35 MiB/s, done.\n",
            "Resolving deltas: 100% (305/305), done.\n",
            "Checking out files: 100% (1738/1738), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Afd8AhjpOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7W7OqGNkO_n",
        "colab_type": "text"
      },
      "source": [
        "## Spark instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2czr5hR8Gm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark as fs\n",
        "fs.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdPinlC45aKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "APP_NAME = \"Playgrounds\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "\n",
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brBIgXkbi7i2",
        "colab_type": "text"
      },
      "source": [
        "## Spark code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljs5HTYchyT7",
        "colab_type": "code",
        "outputId": "1f50414d-99b3-4b39-aa5c-567713a348ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!head /content/Spark-The-Definitive-Guide/data/flight-data/csv/2015-summary.csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEST_COUNTRY_NAME,ORIGIN_COUNTRY_NAME,count\n",
            "United States,Romania,15\n",
            "United States,Croatia,1\n",
            "United States,Ireland,344\n",
            "Egypt,United States,15\n",
            "United States,India,62\n",
            "United States,Singapore,1\n",
            "United States,Grenada,62\n",
            "Costa Rica,United States,588\n",
            "Senegal,United States,40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rof2oTTukk0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = spark.read.option(\"header\", \"true\").csv('/content/Spark-The-Definitive-Guide/data/flight-data/csv/2015-summary.csv')\n",
        "df.createOrReplaceTempView(\"dfTable\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QO82vP6RP4n",
        "colab_type": "code",
        "outputId": "dc292bcf-1c6d-419b-d261-02ce5eace56d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
            " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
            " |-- count: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6yQ0hKcRWV1",
        "colab_type": "code",
        "outputId": "33d7ec75-1c36-4eea-d581-26d396eece6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# create own DataFrame\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
        "\n",
        "mySchema = StructType([\n",
        "  StructField(\"name\", StringType(), False),\n",
        "  StructField(\"age\", LongType(), False)     \n",
        "])\n",
        "\n",
        "myRow = Row(\"Peter\", 23)\n",
        "myDf = spark.createDataFrame([myRow], mySchema)\n",
        "myDf.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|Peter| 23|\n",
            "+-----+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8L-KmJ0EEA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "ca782927-ac51-4526-8b96-500ff0e67e5b"
      },
      "source": [
        "# select and selectExpr\n",
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "df.select(\"DEST_COUNTRY_NAME\").show(2)\n",
        "df.select(col(\"ORIGIN_COUNTRY_NAME\")).show(2)\n",
        "\n",
        "# expr \n",
        "df.select(expr(\"length(DEST_COUNTRY_NAME)\")).show(2)\n",
        "\n",
        "# adding column\n",
        "df.selectExpr(\"*\", \"(DEST_COUNTRY_NAME=ORIGIN_COUNTRY_NAME) as INTERNAL_FLIGHT\").show(2)\n",
        "\n",
        "# aggregates\n",
        "df.selectExpr(\"avg(count)\", \"count(distinct(DEST_COUNTRY_NAME))\").show(2)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|DEST_COUNTRY_NAME|\n",
            "+-----------------+\n",
            "|    United States|\n",
            "|    United States|\n",
            "+-----------------+\n",
            "only showing top 2 rows\n",
            "\n",
            "+-------------------+\n",
            "|ORIGIN_COUNTRY_NAME|\n",
            "+-------------------+\n",
            "|            Romania|\n",
            "|            Croatia|\n",
            "+-------------------+\n",
            "only showing top 2 rows\n",
            "\n",
            "+-------------------------+\n",
            "|length(DEST_COUNTRY_NAME)|\n",
            "+-------------------------+\n",
            "|                       13|\n",
            "|                       13|\n",
            "+-------------------------+\n",
            "only showing top 2 rows\n",
            "\n",
            "+-----------------+-------------------+-----+---------------+\n",
            "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|INTERNAL_FLIGHT|\n",
            "+-----------------+-------------------+-----+---------------+\n",
            "|    United States|            Romania|   15|          false|\n",
            "|    United States|            Croatia|    1|          false|\n",
            "+-----------------+-------------------+-----+---------------+\n",
            "only showing top 2 rows\n",
            "\n",
            "+--------------------------+---------------------------------+\n",
            "|avg(CAST(count AS DOUBLE))|count(DISTINCT DEST_COUNTRY_NAME)|\n",
            "+--------------------------+---------------------------------+\n",
            "|               1770.765625|                              132|\n",
            "+--------------------------+---------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}