{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "omWBpXB9kJfI",
        "e7W7OqGNkO_n"
      ],
      "authorship_tag": "ABX9TyM6VvdOekhDTRjsLlCpy5Ul"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omWBpXB9kJfI",
        "colab_type": "text"
      },
      "source": [
        "## Spark setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqUjdzxOxjS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q http://apache.forsale.plus/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbF-156IyN8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xf /content/spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwltzcJK5QBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcHgm_-9zaFd",
        "colab_type": "code",
        "outputId": "b7df99de-b586-4ad7-abba-29dbff447090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 59kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=688afc41b97ec4f8f2a4fbaa732c8d53fb52f6f31329c6c7ed4dd10247e7094f\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV8frwhSjoaa",
        "colab_type": "code",
        "outputId": "2e777924-5011-4604-b8f2-c56aa8a5e65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/databricks/Spark-The-Definitive-Guide.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Spark-The-Definitive-Guide'...\n",
            "remote: Enumerating objects: 2035, done.\u001b[K\n",
            "remote: Total 2035 (delta 0), reused 0 (delta 0), pack-reused 2035\u001b[K\n",
            "Receiving objects: 100% (2035/2035), 523.88 MiB | 30.90 MiB/s, done.\n",
            "Resolving deltas: 100% (305/305), done.\n",
            "Checking out files: 100% (1738/1738), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Afd8AhjpOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7W7OqGNkO_n",
        "colab_type": "text"
      },
      "source": [
        "## Spark instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2czr5hR8Gm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark as fs\n",
        "fs.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdPinlC45aKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "APP_NAME = \"Playgrounds\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "\n",
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brBIgXkbi7i2",
        "colab_type": "text"
      },
      "source": [
        "## Spark code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljs5HTYchyT7",
        "colab_type": "code",
        "outputId": "cb9cd906-3825-4ca5-903f-1fa43be1951a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!head /content/Spark-The-Definitive-Guide/data/flight-data/csv/2015-summary.csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEST_COUNTRY_NAME,ORIGIN_COUNTRY_NAME,count\n",
            "United States,Romania,15\n",
            "United States,Croatia,1\n",
            "United States,Ireland,344\n",
            "Egypt,United States,15\n",
            "United States,India,62\n",
            "United States,Singapore,1\n",
            "United States,Grenada,62\n",
            "Costa Rica,United States,588\n",
            "Senegal,United States,40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rof2oTTukk0V",
        "colab_type": "code",
        "outputId": "c55db0e8-aaf4-47eb-cff7-04ddfe1dcd66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "flightData2015 = spark.read.option(\"header\", \"true\").csv('/content/Spark-The-Definitive-Guide/data/flight-data/csv/2015-summary.csv')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,StringType,true)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QO82vP6RP4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d1dc7feb-50ee-475f-966e-e740fde38e01"
      },
      "source": [
        "flightData2015.printSchema()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
            " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
            " |-- count: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6yQ0hKcRWV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "39949fc9-8cb6-44e8-df2d-ca36e2b96a08"
      },
      "source": [
        "# create own DataFrame\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
        "\n",
        "mySchema = StructType([\n",
        "  StructField(\"name\", StringType(), False),\n",
        "  StructField(\"age\", LongType(), False)     \n",
        "])\n",
        "\n",
        "myRow = Row(\"Peter\", 23)\n",
        "myDf = spark.createDataFrame([myRow], mySchema)\n",
        "myDf.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|Peter| 23|\n",
            "+-----+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}